# Proyecto Telco Churn ‚Äì Pipeline DVC y MLflow

## 1. Descripci√≥n general

El presente proyecto forma parte de la materia **Laboratorio de Miner√≠a de Datos II (ISTEA)** y tiene por objetivo desarrollar un pipeline reproducible de Machine Learning orientado a predecir la **renuncia de clientes (Churn)** en un servicio de telecomunicaciones.

El trabajo se organiza en etapas progresivas que integran herramientas de versionado de datos (**DVC**), seguimiento de experimentos (**MLflow**) y control de versiones (**Git/DagsHub**).

---

## 2. Estructura general del proyecto

```
Telco_Churn_ML_Pipeline/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Datos originales
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Datos limpios y transformados
‚îÇ   ‚îî‚îÄ‚îÄ prepared/           # Datos listos para modelado
‚îÇ
‚îú‚îÄ‚îÄ models/                 # Modelos entrenados
‚îú‚îÄ‚îÄ params/                 # Par√°metros e hiperpar√°metros
‚îú‚îÄ‚îÄ src/                    # Scripts principales
‚îÇ   ‚îú‚îÄ‚îÄ make_data.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_data.py
‚îÇ   ‚îî‚îÄ‚îÄ train.py
‚îÇ
‚îú‚îÄ‚îÄ dvc.yaml                # Definici√≥n del pipeline DVC
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias del entorno
‚îî‚îÄ‚îÄ README.md
```

---

## 3. Etapas del proyecto

### **Etapa 1 ‚Äî Setup inicial**
- Creaci√≥n del entorno local con **conda** y archivo `requirements.txt`.
- Configuraci√≥n del repositorio Git y conexi√≥n con **DagsHub**.
- Estructuraci√≥n de carpetas y carga del dataset crudo (`data/raw/telco_churn.csv`).
- Versionado inicial del dataset con **DVC**.

**Entregable:** repositorio con estructura base y dataset versionado.


### **Etapa 2 ‚Äî Limpieza y features**
- Implementaci√≥n de los procesos de preparaci√≥n de datos.

> **Nota:** en lugar de un √∫nico archivo `data_prep.py`, se desdobl√≥ la etapa de preparaci√≥n de datos en dos scripts para seguir una estructura m√°s modular:
> - `make_data.py`: lectura e ingesta del dataset crudo.
> - `preprocess_data.py`: limpieza y generaci√≥n de variables derivadas.

- Generaci√≥n del dataset limpio (`data/processed`) y del dataset preparado (`data/prepared`).
- Actualizaci√≥n del archivo `dvc.yaml` con los nuevos *stages* correspondientes.

**Entregable:** pipeline reproducible con datasets crudo, limpio y preparado versionados.


### **Etapa 3 ‚Äî Entrenamiento de modelo**
- Implementaci√≥n del script `train.py` con un modelo base de **Regresi√≥n Log√≠stica**.
- Lectura de hiperpar√°metros desde `params/logreg.yaml`.
- Registro autom√°tico de m√©tricas y artefactos con **MLflow**.
- Integraci√≥n de **DVC** para versionar el modelo y el archivo de m√©tricas (`metrics.json`).

**Entregable:** modelo entrenado, m√©tricas registradas y pipeline completo hasta la etapa de entrenamiento.

---

## 4. Ejecuci√≥n del pipeline

### 4.1 Configuraci√≥n de credenciales (solo una vez por sesi√≥n)
```bash
set MLFLOW_TRACKING_URI=https://dagshub.com/fernandezelias/Telco_Churn_ML_Pipeline.mlflow
set MLFLOW_TRACKING_USERNAME=fernandezelias
set MLFLOW_TRACKING_PASSWORD=<TOKEN_PERSONAL>
```

### 4.2 Ejecuci√≥n completa del pipeline
```bash
dvc repro
```

### 4.3 Versionado y registro de cambios
```bash
dvc push
git add .
git commit -m "Entrega Etapa 3 - Entrenamiento Telco Churn"
git push
```

---

## 5. Pr√≥ximos pasos (Etapa 4)

- Evaluar distintos modelos supervisados (√°rboles, bosques aleatorios, etc.).  
- Optimizar hiperpar√°metros mediante *Grid Search* o *Random Search*.  
- Implementar visualizaciones comparativas de m√©tricas.  
- Documentar los resultados finales en el repositorio de DagsHub.

---

## 6. Autor

‚úçÔ∏è **Autor:** El√≠as Fern√°ndez  
üìß **Contacto:** fernandezelias86@gmail.com  
üèõÔ∏è **Instituci√≥n:** Instituto Superior del Tiempo y Espacio Aplicado (ISTEA)  
üìÜ **Etapa entregada:** Etapa 3 ‚Äì Entrenamiento del modelo
