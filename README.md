# Proyecto Telco Churn ‚Äì Pipeline DVC y MLflow

## üé• Video de presentaci√≥n del proyecto 
üîó https://drive.google.com/file/d/193S2B7LXzIZteEYVEh_pgidtS5NrmDru/view?usp=drive_link

## Resumen ejecutivo

Este proyecto implementa un pipeline completo y reproducible de Machine Learning para predecir el churn en una empresa de telecomunicaciones, integrando herramientas de MLOps modernas como **DVC**, **MLflow**, **GitHub Actions** y **DagsHub**. A lo largo de siete etapas progresivas, el trabajo aborda desde la ingesta y limpieza de datos hasta la experimentaci√≥n controlada, validaci√≥n autom√°tica mediante CI/CD y evaluaci√≥n avanzada del modelo para su eventual despliegue.  
El pipeline permite versionar datasets, modelos y artefactos, registrar m√©tricas comparables y garantizar la reproducibilidad total mediante `dvc repro`. El mejor modelo alcanzado (Regresi√≥n Log√≠stica con regularizaci√≥n d√©bil) se integra a un flujo profesional que refleja buenas pr√°cticas de ingenier√≠a y ciencia de datos aplicadas a un caso real de churn.

## Descripci√≥n general

Este proyecto se desarrolla en el marco de la materia **Laboratorio de Miner√≠a de Datos II (ISTEA)** y tiene como objetivo construir un **pipeline completo, reproducible y trazable de Machine Learning** para predecir la **renuncia de clientes (Churn)** en una empresa de telecomunicaciones.

El enfoque combina varias herramientas clave del ecosistema de Ciencia de Datos y MLOps:

- **DVC** ‚Üí para el versionado de datos, modelos y artefactos.
- **MLflow** ‚Üí para registrar m√©tricas, par√°metros y experimentos.
- **Git + GitHub** ‚Üí para control de versiones del c√≥digo y trabajo colaborativo.
- **DagsHub** ‚Üí como repositorio centralizado para sincronizar datos, modelos y experimentos.

La integraci√≥n de estas tecnolog√≠as permite:

- Garantizar **reproducibilidad total** del pipeline mediante *dvc repro*.
- Versionar todos los artefactos relevantes (**datasets, modelos, m√©tricas, plots**).
- Registrar la evoluci√≥n del experimento bajo un flujo profesional de MLOps.
- Ejecutar validaci√≥n continua del pipeline gracias a **GitHub Actions**.
- Comparar modelos y documentar su desempe√±o de manera transparente.

En conjunto, este proyecto constituye un ejemplo completo de c√≥mo estructurar, entrenar, evaluar y versionar modelos de Machine Learning dentro de un entorno acad√©mico alineado con pr√°cticas profesionales de la industria.

---

## Estructura general del proyecto

```
Telco_Churn_ML_Pipeline/
‚îÇ
‚îú‚îÄ‚îÄ .dvc/
‚îÇ   ‚îî‚îÄ‚îÄ config
‚îÇ
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci.yml
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ prepared/
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ telco_logreg.pkl
‚îÇ   ‚îú‚îÄ‚îÄ telco_tree.pkl
‚îÇ   ‚îî‚îÄ‚îÄ test_model.pkl
‚îÇ
‚îú‚îÄ‚îÄ params/
‚îÇ   ‚îú‚îÄ‚îÄ logreg.yaml
‚îÇ   ‚îî‚îÄ‚îÄ decision_tree.yaml
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ make_data.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_data.py
‚îÇ   ‚îî‚îÄ‚îÄ train.py
‚îÇ
‚îú‚îÄ‚îÄ dvc.yaml
‚îú‚îÄ‚îÄ dvc.lock
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## Resumen de etapas y entregables

| Etapa | Descripci√≥n | Entregable principal |
|-------|-------------|----------------------|
| **1 ‚Äî Setup inicial** | Configuraci√≥n del entorno, repositorio, estructura base y conexi√≥n con DagsHub. | Repo estructurado + dataset crudo versionado en DVC. |
| **2 ‚Äî Limpieza y features** | Ingesta, limpieza, codificaci√≥n, escalado y generaci√≥n de variables derivadas. | Dataset limpio y preparado versionado en DVC. |
| **3 ‚Äî Entrenamiento de modelo** | Implementaci√≥n de `train.py`, lectura de par√°metros y registro de m√©tricas. | Modelo entrenado + m√©tricas registradas + artefactos versionados. |
| **4 ‚Äî Experimentos** | Variaci√≥n controlada del hiperpar√°metro C y an√°lisis comparativo. | Reporte de experimentos y selecci√≥n del mejor modelo. |
| **5 ‚Äî CI/CD con GitHub Actions** | Workflow de validaci√≥n autom√°tica del pipeline (`dvc pull` + `dvc repro`). | Pull Request validado correctamente por CI. |
| **6 ‚Äî Iteraci√≥n colaborativa** | Ramas `feat-*`, PRs, experimentos aislados y validaci√≥n con CI. | Historial de ramas, PRs y merges documentados. |
| **7 ‚Äî Evaluaci√≥n avanzada (Producci√≥n)** | `evaluate.py`, m√©tricas extendidas, curva ROC y artefactos finales. | Pipeline listo para evaluaci√≥n avanzada y pre-despliegue. |

---

## Desarrollo del proyecto

### Etapa 1 ‚Äì Configuraci√≥n inicial

La primera etapa del proyecto tuvo como objetivo preparar el entorno de trabajo y sentar las bases del pipeline completo de Machine Learning. Para ello se realizaron las siguientes tareas:

- **Creaci√≥n del entorno de trabajo con conda**, instalando todas las dependencias definidas en `requirements.txt` para asegurar un entorno reproducible y aislado.

- **Inicializaci√≥n del repositorio en GitHub**, configurando el control de versiones del proyecto y manteniendo el historial completo de cambios del pipeline.

- **Conexi√≥n del repositorio con DagsHub** mediante la configuraci√≥n de un remoto adicional en DVC. Esto permiti√≥ contar con un almacenamiento externo para los datos versionados y habilitar funciones adicionales como el MLflow remoto.

- **Definici√≥n de la estructura base del proyecto**, incluyendo carpetas clave como:
  - `src/` para scripts de procesamiento y entrenamiento  
  - `data/raw/` para el dataset original  
  - `models/` para almacenar artefactos generados  
  - `.github/workflows/` para la configuraci√≥n de CI  

- **Versionado del dataset crudo con DVC**, subi√©ndolo al remoto configurado en DagsHub. Esto garantiza trazabilidad sobre futuras transformaciones, limpieza y preparaci√≥n de datos.

üëâ **Entregable de la etapa:**  
Repositorio estructurado, entorno configurado, dataset crudo versionado con DVC y sincronizaci√≥n correcta con GitHub + DagsHub.

---

### Etapa 2 ‚Äì Limpieza y generaci√≥n de variables

En esta etapa se implement√≥ el proceso de preparaci√≥n de datos necesario para que el pipeline pueda operar sobre informaci√≥n consistente, estandarizada y apta para el entrenamiento de modelos.

Las principales tareas realizadas fueron:

- **`make_data.py` ‚Äî Ingesta del dataset crudo:**  
  Se carg√≥ el dataset original desde `data/raw/` y se verific√≥ su estructura, tipos de datos y presencia de valores faltantes. Este archivo act√∫a como punto de entrada del pipeline y garantiza que el dataset crudo est√© siempre versionado mediante DVC.

- **`preprocess_data.py` ‚Äî Limpieza y transformaci√≥n del dataset:**  
  - Imputaci√≥n y tratamiento de valores ausentes.  
  - Codificaci√≥n de variables categ√≥ricas mediante *One-Hot Encoding* y transformaciones num√©ricas seg√∫n corresponda.  
  - Estandarizaci√≥n / normalizaci√≥n de variables relevantes.  
  - Generaci√≥n de **variables derivadas** necesarias para mejorar el rendimiento del modelo.  
  - Consolidaci√≥n de todas las transformaciones en un dataset final *prepared*.

- **Versionado del dataset limpio y preparado con DVC:**  
  Tanto el dataset procesado (`data/processed/`) como el dataset final preparado (`data/prepared/`) fueron versionados con DVC, asegurando trazabilidad completa en cada ejecuci√≥n del pipeline.

üëâ **Entregable de la etapa:**  
Pipeline reproducible que incluye dataset crudo, dataset limpio y dataset preparado, todos versionados correctamente mediante DVC.

---

### Etapa 3 ‚Äì Entrenamiento del modelo

En esta etapa se desarroll√≥ el m√≥dulo responsable del entrenamiento del modelo base del proyecto. El objetivo fue construir un componente reproducible que tome los datos preparados, lea los hiperpar√°metros desde una configuraci√≥n externa y produzca un modelo versionado.

Las acciones principales fueron:

- **Modelo base: Regresi√≥n Log√≠stica**  
  Se implement√≥ un modelo de clasificaci√≥n utilizando `LogisticRegression`, elegido como baseline por su interpretabilidad y comportamiento estable en problemas de churn.

- **Lectura de hiperpar√°metros desde `params/logreg.yaml`**  
  El script `src/train.py` recupera autom√°ticamente los par√°metros (regularizaci√≥n, solver, iteraciones, random_state, etc.) desde un archivo YAML, asegurando reproducibilidad total del entrenamiento.

- **Registro de m√©tricas y par√°metros en MLflow**  
  Cada ejecuci√≥n documenta:  
  - Hiperpar√°metros utilizados  
  - Accuracy, Precision, Recall, F1 y ROC AUC  
  - Artefactos generados  
  Esto facilita la comparaci√≥n de experimentos en fases posteriores.

- **Versionado del modelo entrenado con DVC**  
  El modelo producido (`models/telco_logreg.pkl`) queda registrado como *artifact* del pipeline.  
  Esto permite:  
  - reproducir entrenamientos,  
  - mantener historial de versiones,  
  - y sincronizar los artefactos con DagsHub.

üëâ **Entregable de la etapa:**  
Modelo base entrenado, m√©tricas registradas, hiperpar√°metros centralizados y artefactos versionados mediante DVC, integrados a la ejecuci√≥n completa del pipeline.

---

### Etapa 4 ‚Äì Ejecuci√≥n de experimentos y an√°lisis comparativo

En esta etapa se realizaron m√∫ltiples ejecuciones del modelo base modificando el hiperpar√°metro de regularizaci√≥n **C** de la Regresi√≥n Log√≠stica. El objetivo fue evaluar c√≥mo influye la fuerza de regularizaci√≥n en el rendimiento del modelo y seleccionar la mejor configuraci√≥n.

Para gestionar los experimentos se utiliz√≥ **MLflow en DagsHub**, lo que permiti√≥ registrar autom√°ticamente:
- par√°metros utilizados,
- m√©tricas producidas,
- artefactos generados en cada run,
- historial completo de ejecuciones.

---

#### 4.1 Configuraci√≥n de credenciales para MLflow (DagsHub)

Antes de ejecutar los experimentos, se configuraron las variables de entorno:

```
set MLFLOW_TRACKING_URI=https://dagshub.com/fernandezelias/Telco_Churn_ML_Pipeline.mlflow
set MLFLOW_TRACKING_USERNAME=fernandezelias
set MLFLOW_TRACKING_PASSWORD=<TOKEN_PERSONAL>
```

---

#### 4.2 Ejecuci√≥n del pipeline para cada experimento

Para cada valor de **C**, se actualiz√≥ el archivo `params/logreg.yaml` y luego se ejecut√≥:

```
dvc repro
```

Esto garantiz√≥ una ejecuci√≥n completamente reproducible del pipeline, regenerando m√©tricas, artefactos y registrando cada run en MLflow.

---

#### 4.3 Versionado de artefactos

Despu√©s de cada experimento, se versionaron los cambios con DVC y Git:

```
dvc push
git add .
git commit -m "Entrega Etapa 4 - Experimentos con regularizaci√≥n"
git push
```

---

#### 4.4 Comparaci√≥n exhaustiva de modelos

Adem√°s del an√°lisis general de la etapa, se realiz√≥ una comparaci√≥n m√°s detallada del comportamiento del modelo de Regresi√≥n Log√≠stica frente a diferentes niveles de regularizaci√≥n (*C*). Esta comparaci√≥n extendida permite evaluar no solo las m√©tricas finales, sino tambi√©n la estabilidad, consistencia y sensibilidad del modelo frente a cambios en su configuraci√≥n.

##### Comportamiento general del modelo
La regularizaci√≥n controla la complejidad del modelo:  
- Valores **peque√±os** de *C* ‚Üí **mayor regularizaci√≥n** ‚Üí modelo m√°s simple y estable.  
- Valores **grandes** de *C* ‚Üí **menor regularizaci√≥n** ‚Üí modelo m√°s flexible, potencialmente m√°s sensible al ruido.

En un problema de churn ‚Äîdonde existe desbalance moderado y m√∫ltiples variables categ√≥ricas‚Äî la estabilidad del modelo es tan importante como la m√©trica final.

##### Resultados obtenidos
La siguiente tabla resume las m√©tricas registradas para las cinco configuraciones evaluadas:

| Run | C | Accuracy | Precision | Recall | F1 | ROC AUC |
|-----|----|----------|-----------|--------|------|----------|
| **1** | 0.5  | 0.6800 | 0.5751 | 0.4580 | 0.5099 | 0.72195 |
| **2** | 1.0  | 0.6800 | 0.5751 | 0.4580 | 0.5099 | 0.72194 |
| **3** | 2.0  | 0.6800 | 0.5751 | 0.4580 | 0.5099 | 0.72194 |
| **4** | 5.0  | 0.6760 | 0.5642 | 0.4773 | 0.5171 | 0.72011 |
| **5** | 10.0 | **0.6845** | **0.5819** | 0.4691 | **0.5194** | **0.72581** |

##### Interpretaci√≥n detallada
- **Alta estabilidad en C=0.5, 1.0 y 2.0:**  
  Estas configuraciones producen m√©tricas pr√°cticamente id√©nticas. Esto indica que la regresi√≥n log√≠stica, con regularizaci√≥n moderada-fuerte, se comporta de manera muy estable frente a la variabilidad del dataset.

- **Primer salto relevante en C=5.0:**  
  Aumenta levemente el *recall* (0.4773) y el *F1-score* (0.5171), lo que sugiere una mayor sensibilidad hacia la clase positiva, aunque con un peque√±o sacrificio en *accuracy*.

- **Mejor configuraci√≥n en C=10.0:**  
  Es la √∫nica que mejora simult√°neamente:
  - **Accuracy**
  - **Precision**
  - **F1-score**
  - **ROC AUC**  

  Logra el equilibrio m√°s s√≥lido entre discriminar correctamente a la clase positiva (churn) y mantener un buen desempe√±o general.

##### S√≠ntesis t√©cnica
- La regresi√≥n log√≠stica es poco sensible a valores de regularizaci√≥n entre 0.5 y 2.0, lo que demuestra que el dataset est√° bien preparado y que el modelo lineal encuentra patrones estables.  
- Las configuraciones de regularizaci√≥n baja (mayor flexibilidad) permiten capturar relaciones adicionales que mejoran levemente el rendimiento sin indicar sobreajuste.  
- El modelo con **C=10** se destaca como mejor candidato para posteriores etapas del pipeline.

Esta comparaci√≥n extendida complementa la tabla principal y justifica la selecci√≥n final de hiperpar√°metros para continuar con el pipeline.

---

### 4.5 Conclusi√≥n de la etapa

- Los modelos con regularizaci√≥n m√°s fuerte (C=0.5‚Äì2.0) mostraron m√©tricas casi id√©nticas, reflejando estabilidad del pipeline.  
- El modelo con **C = 5.0** mejor√≥ levemente recall y F1, aunque con menor accuracy.  
- El modelo con **C = 10.0** obtuvo el **mejor desempe√±o global**, liderando accuracy, precision, F1 y ROC AUC.  
- Todos los experimentos quedaron correctamente registrados en MLflow y versionados con DVC, cumpliendo con las exigencias de reproducibilidad.

üëâ **Entregable de la etapa:** Reporte comparativo de las ejecuciones y registro completo de experimentos en **DagsHub MLflow**, con selecci√≥n fundamentada del mejor modelo.

---

### Etapa 5 ‚Äî CI/CD con GitHub Actions

La etapa 5 incorpora un proceso de **Integraci√≥n Continua (CI)** utilizando **GitHub Actions**, con el objetivo de asegurar que el pipeline completo (gestionado con DVC) se ejecute correctamente cada vez que se realiza un *push* o *pull request* hacia el repositorio.

Este mecanismo permite validar autom√°ticamente la reproducibilidad del workflow, evitando rupturas en el c√≥digo y garantizando que los datos versionados puedan ser descargados y utilizados en un entorno limpio.

---

#### 5.1 Objetivo de la etapa

El workflow de CI debe garantizar que:

- El repositorio puede reconstruirse desde cero en GitHub Actions.
- Las dependencias del proyecto se instalan correctamente.
- Los datos almacenados en DVC Remote (DagsHub) pueden recuperarse mediante `dvc pull`.
- El pipeline completo se ejecuta sin errores con `dvc repro`.
- Las m√©tricas producidas se muestran en el log de ejecuci√≥n.
- Cada *Push* y *Pull Request* activa autom√°ticamente el workflow para su validaci√≥n.

---

#### 5.2 Configuraci√≥n del workflow

El archivo principal del pipeline de CI se encuentra en:

```
.github/workflows/ci.yml
```

Dentro del workflow se implementaron los siguientes pasos:

- **Checkout del repositorio**
- **Instalaci√≥n de dependencias**
- **Configuraci√≥n de DVC** y autenticaci√≥n mediante Secrets (`DAGSHUB_USER`, `DAGSHUB_TOKEN`)
- **Descarga de datos versionados** con `dvc pull`
- **Ejecuci√≥n del pipeline completo** (`dvc repro`)
- **Impresi√≥n de m√©tricas** generadas en la etapa de entrenamiento

Se retiraron dependencias de MLflow en `train.py` para evitar fallos en el entorno de CI.

---

#### 5.3 Validaci√≥n mediante Pull Request

1. Se cre√≥ la rama:
   ```
   feat/ci-validation
   ```
2. Se modific√≥ el archivo `README.md`.
3. Se abri√≥ un Pull Request hacia `main`.
4. GitHub Actions ejecut√≥ el workflow autom√°ticamente.
5. El pipeline finaliz√≥ correctamente:

```
‚úî All checks have passed
‚úî Telco Churn CI / build (pull_request)
```

---

#### 5.4 Estado final de la etapa

‚úî Workflow CI funcionando  
‚úî Validaci√≥n autom√°tica v√≠a Pull Request  
‚úî DVC Remote operativo desde GitHub Actions  
‚úî Pipeline reproducible en entorno externo  
‚úî Revisi√≥n limpia antes del merge  

**Entregable cumplido:** Pull Request validado por CI.

---

### Etapa 6 ‚Äî Iteraci√≥n colaborativa y experimentaci√≥n con ramas

La etapa 6 consisti√≥ en simular un proceso colaborativo basado en **ramas**, **pull requests** y **validaci√≥n autom√°tica por CI**, siguiendo un flujo profesional de experimentaci√≥n con modelos.

El objetivo fue:
- Probar una variante del modelo base (√Årbol de Decisi√≥n).
- Registrar sus par√°metros y artefactos mediante DVC.
- Validar su funcionamiento con el pipeline completo en GitHub Actions.
- Integrarlo a `main` mediante **Pull Request** si el experimento era exitoso.

---

#### 6.1 Creaci√≥n de una rama de experimento

Se cre√≥ una nueva rama de desarrollo:

```
git checkout -b feat/decision-tree
```

Esta rama aloja exclusivamente el experimento con un **DecisionTreeClassifier**.

---

#### 6.2 Nuevo archivo de par√°metros

Se a√±adi√≥ un archivo espec√≠fico:

```
params/decision_tree.yaml
```

Con la siguiente configuraci√≥n:

- `model.type: DecisionTreeClassifier`
- `criterion: gini`
- `max_depth: 5`
- `min_samples_split: 10`
- `random_state: 42`

Esto permite ejecutar el mismo pipeline DVC con un modelo totalmente diferente al de la rama `main`.

---

#### 6.3 Modificaci√≥n temporal del pipeline

La etapa `train` del `dvc.yaml` fue ajustada para utilizar:

- `params/decision_tree.yaml`
- `models/telco_tree.pkl`
- `metrics_tree.json`

Con un comando equivalente a:

```
cmd: python src/train.py --data data/prepared/telco_churn_prepared.csv \
      --model models/telco_tree.pkl \
      --params params/decision_tree.yaml \
      --metrics metrics_tree.json
```

Esto garantiz√≥ que el experimento no afectara la rama principal.

---

#### 6.4 Ejecuci√≥n del pipeline en local

```
dvc repro
```

Resultado principal:

```
accuracy = 0.684
```

El Decision Tree mostr√≥ un rendimiento similar al mejor modelo log√≠stico.

---

#### 6.5 Registro del experimento

```
dvc push
git add .
git commit -m "Experimento: Decision Tree con nuevo params y artefactos DVC"
git push origin feat/decision-tree
```

---

#### 6.6 Pull Request del experimento

Se abri√≥ un PR:

```
feat/decision-tree ‚Üí main
```

GitHub Actions ejecut√≥:

- `dvc pull`
- `dvc repro`
- Verificaci√≥n del pipeline completo

Resultado:

```
‚úî All checks have passed
‚úî Telco Churn CI / build (pull_request)
```

---

#### 6.7 M√©tricas del Decision Tree

| M√©trica | Valor |
|--------|--------|
| Accuracy | **0.684** |
| Precision | similar al baseline |
| Recall | ligeramente inferior |
| F1-score | estable |
| ROC AUC | comparable al log√≠stico |

---

#### 6.8 Merge del experimento a `main`

Aunque el modelo no super√≥ al log√≠stico, se realiz√≥ el merge porque:

- Demuestra flujo colaborativo
- CI valid√≥ completamente el pipeline
- Se preserva hist√≥rico de experimentos

Merge registrado:

```
Merge pull request #3 from fernandezelias/feat/decision-tree
```

---

#### 6.9 Resultado final de la etapa

‚úî Ramas de experimento creadas  
‚úî Modelos alternativos ejecutados  
‚úî Artefactos versionados con DVC  
‚úî CI validando autom√°ticamente cada PR  
‚úî Integraci√≥n final en `main`  
‚úî Documentaci√≥n completa del proceso

**Entregable cumplido.**

---

## Etapa 7 ‚Äî Evaluaci√≥n avanzada y artefactos de producci√≥n (Bonus)

En la etapa 7 se a√±adi√≥ un m√≥dulo de **evaluaci√≥n avanzada del modelo**, generando artefactos propios de un entorno de producci√≥n: m√©tricas completas y curva ROC.

---

### 7.1 Nuevo m√≥dulo: `evaluate.py`

Se incorpor√≥ el archivo:

```
src/evaluate.py
```

Este script permite:

- Cargar un modelo entrenado (`.pkl`).
- Evaluar m√©tricas avanzadas:  
  `accuracy`, `precision`, `recall`, `f1`, `roc_auc`.
- Generar y guardar una **curva ROC**.
- Guardar las m√©tricas en un archivo JSON versionado.

---

### 7.2 Integraci√≥n al pipeline DVC

Se a√±adi√≥ la etapa `evaluate` al `dvc.yaml`:

```yaml
evaluate:
  cmd: python src/evaluate.py --model models/telco_tree.pkl --data data/prepared/telco_churn_prepared.csv --metrics reports/metrics_tree_eval.json --plot reports/roc_tree.png
  deps:
    - src/evaluate.py
    - models/telco_tree.pkl
    - data/prepared/telco_churn_prepared.csv
  outs:
    - reports/metrics_tree_eval.json
    - reports/roc_tree.png
```

---

### 7.3 Ejecuci√≥n del m√≥dulo

```
dvc repro
```

Resultado obtenido:

```
Evaluaci√≥n completada.
{
  "accuracy": 0.6943,
  "precision": 0.6533,
  "recall": 0.3377,
  "f1": 0.4452,
  "roc_auc": 0.7415
}
```

---

### 7.4 Artefactos generados

| Artefacto | Descripci√≥n |
|----------|-------------|
| `reports/metrics_tree_eval.json` | M√©tricas completas del √°rbol de decisi√≥n |
| `reports/roc_tree.png` | Curva ROC generada |

Ambos fueron versionados con:

```
dvc push
```

---

### 7.5 Preparaci√≥n para producci√≥n

Este m√≥dulo permite:

- Evaluar cualquier modelo versionado.
- Integrarse a APIs con **FastAPI** o dashboards en **Streamlit**.
- Servir como paso final del pipeline antes del deploy.

**Etapa 7 completada con √©xito.**

---

## Conclusiones

El desarrollo del **pipeline Telco Churn** permiti√≥ integrar, de manera articulada, t√©cnicas de Machine Learning con pr√°cticas modernas de ingenier√≠a de datos. A lo largo de sus distintas etapas, el proyecto avanz√≥ desde la ingesta y limpieza inicial del dataset hasta la evaluaci√≥n avanzada y la generaci√≥n de artefactos aptos para un entorno de producci√≥n.

El uso de **DVC** garantiz√≥ la trazabilidad completa: cada dataset, modelo, m√©trica y gr√°fico qued√≥ versionado, lo que asegura reproducibilidad total. Por su parte, **GitHub Actions** habilit√≥ validaciones autom√°ticas mediante CI, agregando robustez y control de calidad en cada *push* y *pull request*. La integraci√≥n con **DagsHub** facilit√≥ el seguimiento hist√≥rico de experimentos y m√©tricas, permitiendo comparar modelos de manera transparente.

En cuanto a los resultados model√≠sticos, la **Regresi√≥n Log√≠stica** con regularizaci√≥n d√©bil (C=10) ofreci√≥ el mejor equilibrio entre precisi√≥n, recall, F1 y AUC. El experimento con **√Årbol de Decisi√≥n** mostr√≥ estabilidad y compatibilidad con el pipeline, aunque sin superar al modelo base, evidenciando la importancia de los experimentos controlados en escenarios de churn.

Finalmente, la incorporaci√≥n del m√≥dulo `evaluate.py` permiti√≥ extender el pipeline hacia una fase previa al despliegue, generando m√©tricas avanzadas y visualizaciones propias de un entorno productivo.

En conjunto, el proyecto demuestra:

- un flujo de trabajo profesional basado en control de versiones, datos reproducibles y CI/CD;  
- la capacidad de evaluar y comparar modelos bajo un mismo pipeline;  
- la preparaci√≥n t√©cnica para extender el proyecto hacia APIs (FastAPI) o dashboards (Streamlit);  
- y la consolidaci√≥n de buenas pr√°cticas de ingenier√≠a y ciencia de datos aplicadas a un caso real de churn.

**El pipeline queda as√≠ completamente documentado, versionado y preparado para escalar hacia entornos de producci√≥n o nuevas iteraciones experimentales.**

---

## Integrantes del equipo

- El√≠as Fern√°ndez ‚Äî elias.fernandez@istea.com.ar

- Fiorela Macheroni ‚Äî fiorela.macheroni@istea.com.ar

- Sebasti√°n Fuentes ‚Äî sebastian.fuentes@istea.com.ar

**Instituci√≥n:** ISTEA

**Carrera:** Tecnicatura Superior en Ciencia de Datos e Inteligencia Artificial

**Materia:** Laboratorio de Miner√≠a de Datos  

**Repositorios:**
- GitHub: https://github.com/fernandezelias/Telco_Churn_ML_Pipeline
- DagsHub: https://dagshub.com/fernandezelias/Telco_Churn_ML_Pipeline